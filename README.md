# McDonald's EU Division â€” SQL Case Study ğŸ”

## The Challenge

Imagine you're the newly hired Data Analyst for McDonald's European Division. On your first day, you receive three messy CSV files containing months of transactional dataâ€”sales records, store information, and theft reports scattered across dozens of EU locations. 

Finance needs revenue insights. Compliance is concerned about theft patterns. Marketing wants to understand customer behavior. And everyone needs answers *yesterday*.

Your mission? Clean the chaos, extract actionable insights, and deliver results that drive real business decisions.

---

## ğŸ“Š The Data

This case study works with three interconnected datasets:

- **`Sales.csv`** â€” Line-item transactions: dates, products, prices, quantities, payment methods, store IDs
- **`Store.csv`** â€” Store master data: city, country/region, manager details, operational info  
- **`Theft.csv`** â€” Incident reports: theft amounts, dates, affected stores and managers

> **Note:** All data is synthetically generated for educational purposes. No actual McDonald's data was used.

---

## ğŸ¯ Business Questions Answered

### ğŸ’° Finance Team
*"Show me the moneyâ€”and where it's going."*

1. What are our minimum and maximum product prices?
2. What's the average price point for each product?
3. What's our total revenue across all stores?
4. How many units have we sold?
5. What's our bottom-line profit after costs?

### ğŸ”’ Compliance Team
*"We need to identify and address theft patterns immediately."*

1. How much theft has occurred under each manager's watch?
2. Which managers have experienced more than 10 theft incidents? (Include their demographics, tenure, and location for pattern analysis)

### ğŸ“ˆ Marketing Team
*"Help us understand our customers and optimize our strategy."*

1. Which country is driving the most unit sales?
2. How are customers paying? (Payment method breakdown)
3. Where are they ordering from? (In-store vs. Drive-thru vs. Online)
4. Which products are our star performers? (Ranked by volume)

---

## ğŸ” Key Insights

### Financial Performance
- **Total Revenue:** **$8,031,166**  
- **Total Cost:** **$1,382,379**  
- **Total Profit:** **$5,707,702** (71% profit margin ğŸ‰)
- **Units Sold:** **1,382,379** items
- **Price Range:** **$2.95 â€“ $12.99**

### Market Intelligence
- **Top Market:** Spain leads with **154,922 units** (**11.21%** of total volume)
- **Best-Seller:** Fries dominate with **561,951 units sold** (the people have spoken!)

### Customer Behavior
**Payment Preferences:**
- Credit Card: **80.0%** (digital-first customers)
- Cash: **17.3%** (still relevant)
- Gift Card: **2.7%** (growth opportunity?)

**Purchase Channels:**
- In-Store: **48.6%** (traditional dining experience)
- Drive-Thru: **46.3%** (convenience is king)
- Online: **5.1%** (emerging channel to watch)

> ğŸ’¡ **Insight:** Nearly half of all transactions happen through drive-thru, suggesting customers value speed and convenience. Online ordering, while small, represents a significant growth opportunity.

---

## ğŸ“ Repository Structure

```
Mc-Donalds-SQL-Case-Study/
â”‚
â”œâ”€â”€ data/                                    # Raw data files
â”‚   â”œâ”€â”€ Sales.csv
â”‚   â”œâ”€â”€ Store.csv
â”‚   â””â”€â”€ Theft.csv
â”‚
â”œâ”€â”€ queries/                                 # SQL scripts (numbered execution order)
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”œâ”€â”€ AVG.sql                             # Average price calculations
â”‚   â”œâ”€â”€ Altering table to split columns.sql # Data cleaning operations
â”‚   â”œâ”€â”€ Check duplicate values.sql          # Data quality checks
â”‚   â”œâ”€â”€ Compliance analysis.sql             # Theft and manager analysis
â”‚   â”œâ”€â”€ Delete duplicates.sql               # Duplicate removal
â”‚   â”œâ”€â”€ Exercises.sql                       # Practice queries
â”‚   â”œâ”€â”€ Fix typos.sql                       # Data standardization
â”‚   â”œâ”€â”€ Fixing column Header typo.sql       # Column name corrections
â”‚   â”œâ”€â”€ MAX MIN.sql                         # Price range analysis
â”‚   â”œâ”€â”€ Payment by ratio.sql                # Payment method distribution
â”‚   â”œâ”€â”€ Products DESC.sql                   # Product ranking
â”‚   â”œâ”€â”€ Purchase by ratio.sql               # Purchase channel analysis
â”‚   â”œâ”€â”€ Splitting columns.sql               # Column parsing
â”‚   â”œâ”€â”€ TotalCost.sql                       # Cost calculations
â”‚   â”œâ”€â”€ TotalProfit.sql                     # Profit calculations
â”‚   â”œâ”€â”€ TotalRevenue.sql                    # Revenue calculations
â”‚   â”œâ”€â”€ deleting columns.sql                # Schema cleanup
â”‚   â””â”€â”€ populating splitted columns.sql     # Derived column population
â”‚
â”œâ”€â”€ results/                                 # Query outputs (CSV exports)
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”œâ”€â”€ AVG.csv
â”‚   â”œâ”€â”€ Compliance Analysis.csv             # Managers with theft > 10 incidents
â”‚   â”œâ”€â”€ Country Quantity Sold.csv
â”‚   â”œâ”€â”€ Max & Min Price.csv
â”‚   â”œâ”€â”€ Payment by Ratio.csv
â”‚   â”œâ”€â”€ Products Desc.csv
â”‚   â”œâ”€â”€ Purchase by Ratio.csv
â”‚   â”œâ”€â”€ Total Costs.csv
â”‚   â”œâ”€â”€ Total Profit.csv
â”‚   â””â”€â”€ Total Revenue.csv
â”‚
â””â”€â”€ README.md                                # You are here!
```

---

## ğŸ› ï¸ SQL Techniques Demonstrated

### Data Cleaning & Preparation
- **Column standardization:** Trimming whitespace, fixing typos, renaming headers
- **Type casting:** Converting string dates to proper DATE types, ensuring numeric fields
- **Duplicate detection & removal:** Using window functions and CTEs to identify and eliminate duplicates
- **Schema restructuring:** Splitting combined columns, dropping unnecessary fields

### Analysis & Aggregation
- **Core aggregations:** `SUM`, `AVG`, `MIN`, `MAX` for KPI calculations
- **Window functions:** Rankings and running totals where supported
- **Ratio calculations:** Using `SUM(CASE WHEN ...) / SUM(...)` for clean percentage breakdowns
- **Multi-table joins:** Connecting sales, store, and theft data for comprehensive analysis

### Business Logic Implementation
- **Revenue:** `SUM(price Ã— quantity)`
- **Cost:** `SUM(cost_per_unit Ã— quantity)`  
- **Profit:** `Revenue - Cost`
- **Mix analysis:** Category proportions with two decimal precision

### Best Practices
- **One query = one business question** (easy to understand and maintain)
- **Reusable CTEs/views** to avoid repeating logic
- **Clear naming conventions** for queries and outputs
- **CSV-ready result sets** for immediate stakeholder consumption

---

## ğŸš€ How to Use This Project

1. **Clone the repository**
   ```bash
   git clone https://github.com/nicobeltran7/Mc-Donalds-SQL-Case-Study.git
   cd Mc-Donalds-SQL-Case-Study
   ```

2. **Load the data**
   - Import the three CSV files from `/data/` into your SQL database
   - Recommended: SQLite for quick local setup, or PostgreSQL/MySQL for production-like environment

3. **Run the queries**
   - Execute scripts in `/queries/` in order (start with cleaning scripts)
   - Each query is self-contained and documented
   - Results will match those in `/results/` folder

4. **Explore and extend**
   - Modify queries to answer your own business questions
   - Add new analyses based on different dimensions
   - Practice different SQL techniques and optimizations

---

## ğŸ’¡ Next Steps & Extensions

### ğŸ“Š Build a Dashboard
Transform these insights into an executive dashboard:
- **Tool:** Power BI, Tableau, or Looker
- **Key visuals:** 
  - KPI cards for Revenue, Profit, and Units Sold
  - Time-series trend for daily/weekly performance
  - Geographic heat map of sales by country
  - Product mix treemap
- **Interactivity:** Date range selector, country filter, payment type slicer

### ğŸ” Advanced Analytics
Take the analysis deeper:
- **Anomaly detection:** Implement z-score or IQR methods to flag unusual revenue or theft patterns
- **Cohort analysis:** Track customer behavior over time
- **Basket analysis:** Which products are frequently purchased together?
- **Forecasting:** Predict next quarter's sales using historical trends

### âš¡ Performance Optimization
Scale for production workloads:
- **Indexing strategy:** Add indexes on `store_id`, `sale_date`, and other frequently filtered columns
- **Partitioning:** Split large tables by date range for faster queries
- **Materialized views:** Pre-compute expensive aggregations
- **Query optimization:** Analyze execution plans and eliminate bottlenecks

### ğŸ§ª Data Quality Framework
Ensure data reliability:
- **Automated checks:** Null counts, duplicate detection, value range validation
- **Scheduled monitoring:** Daily data quality reports
- **Alert system:** Notify stakeholders when anomalies are detected
- **Documentation:** Maintain a data dictionary with business definitions

### ğŸ“š Documentation Enhancement
Make this project portfolio-ready:
- **Data Dictionary:** Document every field, its meaning, and data type
- **KPI Glossary:** Define exactly how each metric is calculated
- **Process Flow Diagram:** Visualize the ETL and analysis pipeline
- **Screenshots:** Include sample outputs and (if built) dashboard previews

---

## ğŸ“ Skills Demonstrated

This project showcases:
- âœ… **Data Cleaning:** Handling messy real-world data with SQL
- âœ… **SQL Proficiency:** Complex queries, joins, aggregations, window functions
- âœ… **Business Acumen:** Translating stakeholder questions into actionable analysis
- âœ… **Problem-Solving:** Working through data quality issues systematically
- âœ… **Documentation:** Clear, professional README and query organization
- âœ… **Attention to Detail:** Accurate calculations with proper business context

---
